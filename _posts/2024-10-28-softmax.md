---
layout: post
title: "Understanding Softmax Function"
date: 2024-10-28
tags: ["Machine Learning"]
---


---
## Definition
- To interpret these logits as probabilities, we usually apply the softmax function, which converts the logits into values between 0 and 1 that sum to 1
- Softmax is defined as follows

$$ Softmax(z) = \frac {e^{z_j}}{\sum_{j} {1+e^{z_j}}} $$

---
## Implementation

### Formulation
```
def softmax(z):
    return z.exp()/(z.exp().sum(-1)).unsqueeze(1)

>>> yhat = softmax(z)
>>> yhat
tensor([[0.2312, 0.1402, 0.6285],
        [0.0674, 0.8214, 0.1112]])
```

---
### Validation
- Note that, for each example row, the probabilities now sum to 1

```
0.2312 + 0.1402 + 0.6285 = 1.0
0.0674 + 0.8214 + 0.1112 = 1.0
```

---
### Verification
- This can be verified using PyTorch implementation

```
>>> import torch.nn as nn
>>> yhat = nn.functional.softmax(z)
>>> yhat
tensor([[0.2312, 0.1402, 0.6285],
        [0.0674, 0.8214, 0.1112]])
```

---
### Limitations

- Calculating softmax function involves exponentiation of logits
- When logits are large (positive or negative), exponentiation can lead to very large or very small probabilities, approaching the limits of floating-point precision
- This can produce `nan` values as shown below

```
>>> z = torch.tensor([[-1000.0, -1000.0, 1000.0]])
>>> yhat = softmax(z)
>>> yhat
tensor([[0.0000, 0.0000,    nan]])
```

---
## Modified Implementations

### Normalized Softmax

- We know Softmax function is defined as follows

$$ Softmax(z) = \frac {e^{z_j}}{\sum_{j} e^{z_j}} $$

- We can write it as follows

$$ Softmax(z) = \frac {e^{z_j}}{\sum_{j} e^{z_j}} \frac {e^{-z_max}}{e^{-z_max}} $$

$$ Softmax(z) = \frac {e^{z_j-z_max}}{\sum_{j} e^{z_j-z_max}}$$

```
def softmax_norm(z):
    z_max, _ = torch.max(z,-1,keepdim=True)
    z = z - z_max
    return z.exp()/(z.exp().sum(-1)).unsqueeze(1)

>>> z = torch.tensor([[-1000.0, -1000.0, 1000.0]])
>>> softmax_norm(z), nn.functional.softmax(z)
(tensor([[2.3122e-01, 1.4024e-01, 6.2853e-01],
         [6.7425e-02, 8.2141e-01, 1.1117e-01],
         [0.0000e+00, 1.9287e-22, 1.0000e+00],
         [0.0000e+00, 0.0000e+00, 1.0000e+00]]),
 tensor([[2.3122e-01, 1.4024e-01, 6.2853e-01],
         [6.7425e-02, 8.2141e-01, 1.1117e-01],
         [0.0000e+00, 1.9287e-22, 1.0000e+00],
         [0.0000e+00, 0.0000e+00, 1.0000e+00]]))
```