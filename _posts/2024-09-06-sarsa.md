---
layout: post
title: "SARSA: On-Policy TD Control"
date: 2024-09-05
tags: ["Reinforcement Learning"]
---

## Intuition

- SARSA stands for State-Action-Reward-State-Action
- It is an example of on-policy TD prediction methods for the control problem

## Update Rule

- For an on-policy method we must estimate the action value $q_{\pi}(s, a)$ for the current behavior policy $\pi$ and for all states `s` and actions `a`

$$ {q}(S_t,A_t) \leftarrow {q}(S_t,A_t) + \alpha \left (R_{t+1} + \gamma q(S_{t+1},A_{t+1}) - {q}(S_t,A_t) \right ) $$

- This update is done after every transition from a state $S_t$ unless it is a terminal state $S_T$

- If $S_{t+1}$ is terminal then q(S_{t+1},A_{t+1}) = 0

