---
layout: post
title: "AWS Notes - S3"
date: 2025-06-15
tags: ["Cloud"]
---

S3 stands for Simple Storage Service

---
### Introduction

- S3 is object storage
- When you store data in object storage, it's encapsulated into an object
- Objects are accessed using their unique identifier, eliminating the need to traverse a hierarchical file system

---
### Bucket

- Objects are stored in a flat, single-level structure, often called a bucket
- Buckets are created in your account and must have a globally unique name
- Although S3 looks like a global service, buckets are actually created in a specific AWS region

---
### Objects

- objects are files and they have a key which is the full path of your file
- Keys are very long names that contain slashes and are made of a prefix and an object name
- Ex:

```
Path = s3://dan-bucket/images/cars/bentley.jpg

Bucket Name = dan-bucket
Key = images/cars/bentley.jpg
Prefic = images/cars
Object Name = bentley.jpg
```

- Max object size of 5TB supported
- Above 5GB, multi-part upload must be used
- Metadata, tags, and versioning can be associated with objects to enhance management and security.

---
### Security

- Two types of policies
    - User-based - IAM permissions
    - Resource-based - Bucket policies, Access Control Lists (Object level)
- An outside user can access an s3 object if bucket policy allows it i.e. Bucket is public
- An IAM principal can access an s3 object 
    - if IAM permissions ALLOW it or Bucket policies ALLOW it
    - and if there is no explicit DENY
- Objects can be encrypted for security

---
### Versioning

- We can enable versioning of files so that changes are tracked
    - Null versions are assigned to files existing before enabling versioning
    - Adding a new file will assign a version id to it
    - Overwriting the same key (file) will create a new version, make it as current version and mark other versions as non-current version
    - Deleting a key will execute an `Expiration` action
        - creates a new version, adds a Delete Marker to it, makes it as current version and marks other versions as non-current version
    - Deleting a specific version of a key will execute a `NoncurrentVersionExpiration` action
        - deletes it permanently
- Versioning is enabled at bucket level
- Suspending versioning will not delete previous versions

---
### Replication

- Goal: To keep a replica of the data in s3 bucket in one Region to another region
- Two Types
    - Same Region Replication (SRR)
    - Cross Region Replication (CRR)
- Required
    - Versioning must be enabled on both source and destination buckets
    - S3 service must have IAM permission to read from source bucket and write to the destination bucket
- Replication happens asynchronously in the background
- Cross account replication can be done with CRR

---
### S3 Durability

- It refers to the likelihood of losing an object stored in Amazon S3
- S3 offers extremely high durability, known as "11 nines," which means 99.999999999% durability
- It means that if you store 10 million objects, you can expect to lose only one object every 10,000 years on average
- This durability level is consistent across all storage classes

--- 
### S3 Availability

- indicates how readily the S3 service can be accessed
- varies by storage class

---
### S3 Storage Classes

- Standard 
    - frequently accessed data
    - low latency, 99.99% HA
    - used in big data, gaming etc
- Infrequent Access 
    - less frequently accessed data needing rapid access when needed; 
    - less cost than Standard, incurs retrieval cost
    - 99.9% HA, used in disaster recovery, backups
- Intelligent Tiering
    - S3 optimizes storage costs by moving objects across tiers based on usage patterns
    - Allows user to "set and forget"
    - No retrieval fee, incurs auto-tiering fee
- One-Zone Infrequent Access
    - stores data in single AZ (might incur data loss)
    - 99.5% HA
    - used for secondary backup copies of on-premises data (data that can be re-created)
- Glacier Archive - low cost options for archival and backups
    - Instant Retrieval - (ms)
    - Flexible Retrieval - 
        - Expedited - (1-5 min)
        - Standard - (3-5 hrs)
        - Bulk - (5-12 hrs) (free)
    - Deep Archive - lowest cost
        - Standard - (12 hrs)
        - Bulk - (48 hrs)

**Note**

- We can tranisition objects from one storage class to other in top-down way
- Ex: An object can be moved from Standard tier to any other tier below it as shown in previous section

---
### S3 Lifecycle Rules

- Moving objects can be automated using Lifecycle Rules
- Rules can be created for certain S3 prefix or tags
- Transition rules
    - move objects to lower storage class after certain duration
    - Ex: move to Glacier after 6 months
- Expiration rules
    - delete objects after certain period
    - Ex: 
        - delete log file after 1 year
        - delete incomplete multi-part upload
        - delete old versions of files (versioning enabled)

---
### S3 Requester Pays

- Usual bucket 
    - the bucket owner pays the S3 Storage Cost + Networking Cost (download objects)
- In Requester Pays Bucket, 
    - the bucket owner pays the storage cost
    - the requester who wants to download the S3 objects pays the networking cost
- Helpful when we want to share data with other accounts
- (Reqd) The requester must be authenticated in AWS (not anonymous)

---
### S3 Event Notifications

<img src="{{site.url}}/images/aws/s3-events.png">

- Events can be S3.ObjectCreated, S3.ObjectRemoved etc.
- Ex: Create thumbnail of images uploaded to S3 bucket
- S3 sends the event notifications to these services in seconds (or mins)
    - Simple Notification Service (SNS)
    - Simple Queue Service (SQS)
    - Lambda Function
- To send notification, two ways to assign policy
    - S3 can have IAM role with relevant IAM permissions or
    - (Recommended) SNS, SQS, Lambda can have Resource (Access) Policy which allows them to watch for events in particular S3 bucket

<img src="{{site.url}}/images/aws/s3-eventbridge.png">

- AWS EventBridge is new integration that allows S3 to deliver events to multiple services 

---
### S3 Performance

**Overview**

- 3500 Put requests & 5000 Get Requests per second per prefix
- 100-200 ms latency (scales to high request rates)
- no limits to number of prefixes in a bucket

**Multi-part Upload**

- recommended for >100MB, must for >5GB
- speeds up transfers by parallelizing uploads

**S3 Transfer Acceleration**

- transfer file to an AWS edge location over public internet
- upload file to target bucket using AWS private network
- minimize the amount of public network and maximize the amount of AWS network to go through

**S3 Byte-Range Fetches**

- parallize GETs by requesting specific byte ranges
- Can be used to speed up downloads by parallel downloads of 1,2...N byte ranges
- Can be used to fetch specific byte range (e.g. Get CSV header)

---
### S3 Batch Operations

- Can perform Bulk operations on existing S3 Objects with a single request
    - copy objects between s3 buckets
    - restore objects from s3 glacier
    - encrypt all un-enrypted s3 objects
    - modify ACLs, tags
- A Batch Job consists of 
    - a list of s3 objects
    - the action to perform
    - optional params
- Why use it ?
    - AWS managed service
    - automated retries, progress tracking, completion notifications, reports etc.
- How to get list of objects ?
    - use **S3 inventory** to get list of objects
    - use **Athena** to query and filter your objects

---
### S3 Storage Lens

- used to understand, analyze and optimize **storage** across AWS org
- can discover anomalies, identify cost efficiencies and apply data protection best practices
- can configure a dashboard for AWS Org, Account, Region, Bucket or Prefix level
- can generate daily reports to CSV/Parquet